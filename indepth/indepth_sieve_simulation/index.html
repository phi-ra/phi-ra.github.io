<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Philipp  Ratz


  | Simulations and heuristics

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="/phi_logo.ico">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/indepth/indepth_sieve_simulation/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://phi-ra.github.io/">
       <span class="font-weight-bold">Philipp</span>   Ratz
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          <!-- CV -->
          <li class="nav-item ">
            <a class="nav-link" href="/assets/pdf/current_cv.pdf">
              CV
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research/">
                research
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Simulations and heuristics</h1>
    <p class="post-description">Neural Nets as nonparametric estimators</p>
  </header>

  <article>
    <p>In the <a href="/indepth/indepth_sieve_convergence/">theory post on sieves</a> and of course the <a href="https://arxiv.org/abs/2205.07101" target="_blank" rel="noopener noreferrer">Article</a>, we discovered some interesting facts about the rate of convergence of Neural Network type sieve estimators. Namely, whey seem to be less sensitive to the dimensionality of the problem at hand than other well-known nonparametric estimators.</p>

<p>Here you can find the details of some simulations that were run for the article. The goal was to study the properties derived in the <a href="/indepth/indepth_sieve_convergence/">theory post</a> but here with only a finite amount of data.</p>

<h1 id="approximation-and-dimensionality">Approximation and Dimensionality</h1>
<p>The most important feature that we want to study is how ANN-type estimators behave in different dimensional model settings as compared to other nonparametric estimators. Here they are compared to Kernel type estimators. We begin with a simple case, where there are just two relevant predictors and a noise term, the noise term is assumed to come from a normal distribution. We then successively increase the number of noise terms and number of relevant predictors. In short, the setup looks as follows:</p>

<p>The high dimensional model 1 is generated according to the process:
\begin{equation}\label{apB:high_dim_1}
	y_i = \sum_{i=1}^{k}f_i(X_i) + \varepsilon_i
\end{equation}</p>

\[k={2,5,10,15}, \;\;\; X_i=
\begin{cases}
\sim \textnormal{Unif}([0,3]), &amp; \text{relevant} \\
\sim \textnormal{Unif}([-1,1]), &amp; \text{otherwise}
\end{cases}, \;\;\;
\varepsilon_i \sim \mathcal{N}(0, 9^2)\]

<p>To get a variety of different functions that might be hard to approximate using a parametric model, they take the rather funky forms as defined in the table below.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">function</th>
      <th style="text-align: center">definition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">\(f_1\)</td>
      <td style="text-align: center">\(3.5\sin(x)\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_2\)</td>
      <td style="text-align: center">\(8\log (\max(\mid x\mid,1) )\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_3\)</td>
      <td style="text-align: center">\(2x^4\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_4\)</td>
      <td style="text-align: center">\(-0.4(x^2 + x^3 + 0.1\log(\max(\mid x \mid,0.5)))\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_5\)</td>
      <td style="text-align: center">\(-4x^3\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_6\)</td>
      <td style="text-align: center">\(7x^2\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_7\)</td>
      <td style="text-align: center">\(2\log(\max(\mid x\mid, 0.3))^3\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_8\)</td>
      <td style="text-align: center">\(\mid x \mid\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_9\)</td>
      <td style="text-align: center">\(-(0.9x^2 + x^3)/(\max(\sin(x)+2x^5,0.9))\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_{10}\)</td>
      <td style="text-align: center">\(-4\cos(x)\)</td>
    </tr>
    <tr>
      <td style="text-align: center">\(f_{n &gt; 10}\)</td>
      <td style="text-align: center">\(x\)</td>
    </tr>
  </tbody>
</table>

<p>The functions generating the high dimensional model. If the number of relevant predictors exceeds 10, the functions the subsequent predictors are just linear additive terms. Note that <em>all</em> generated models contain the number of nuisance parameters indicated in addition to the gaussian error term.</p>

<p>That much for the setup, now to the results:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"> </th>
      <th style="text-align: center"> </th>
      <th style="text-align: center">Relevant predictors</th>
      <th style="text-align: center"> </th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">Noise Terms</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">5</td>
      <td style="text-align: center">15</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">6.11\(^*\)</td>
      <td style="text-align: center">18.31\(^*\)</td>
      <td style="text-align: center">59.13</td>
    </tr>
    <tr>
      <td style="text-align: center">Local Linear (Kernel)</td>
      <td style="text-align: center">10</td>
      <td style="text-align: center">28.98</td>
      <td style="text-align: center">46.48</td>
      <td style="text-align: center">79.30</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">20</td>
      <td style="text-align: center">44.02</td>
      <td style="text-align: center">66.65</td>
      <td style="text-align: center">97.99</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">22.33</td>
      <td style="text-align: center">33.99</td>
      <td style="text-align: center">41.86\(^*\)</td>
    </tr>
    <tr>
      <td style="text-align: center">ANN</td>
      <td style="text-align: center">10</td>
      <td style="text-align: center">27.10\(^*\)</td>
      <td style="text-align: center">36.85\(^*\)</td>
      <td style="text-align: center">47.03\(^*\)</td>
    </tr>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center">20</td>
      <td style="text-align: center">34.87\(^*\)</td>
      <td style="text-align: center">43.27\(^*\)</td>
      <td style="text-align: center">51.72\(^*\)</td>
    </tr>
  </tbody>
</table>

<p>Here we see the results from 50 simulations each, when we consider the RMSE on a test set. The \(^*\) denotes the lowest RMSE across the two different models.</p>

<h1 id="inference-of-semiparametric-models">Inference of Semiparametric models</h1>
<p>Another interesting part when working with Neural Networks is how they behave if we mix them with a standard parametric model. From an application side, eg <a href="https://doi.org/10.1016/S0925-2312(01)00702-0" target="_blank" rel="noopener noreferrer">Zhang</a> proposed a mix of an ARIMA model with a ANN and found that they perform better as either model in isolation. Further, in the M4 Competition which was analysed by <a href="https://doi.org/10.1016/j.ijforecast.2018.06.0019" target="_blank" rel="noopener noreferrer">Spyros Makridakis and colleagues</a> found that mixing traditional estimators and machine learning models also resulted in the best forecasts throughout the competition. So instead of focusing on the predictive performance, we conduct a simulation that tries to estimate a linear parameter while having nonlinear disturbances that can be estimated with a neural network.</p>

<p>For that we set up a problem that can weight up the benefits of ANNs as compared to parametric models. Consider the following functions, which is closely related to the experiments of <a href="https://doi.org/10.1111/j.1369-7412.2004.05303.x" target="_blank" rel="noopener noreferrer">Gao and Tong</a></p>

\[y_t = \beta_1 v_{t-1} - \beta_2 v_{t-2} + \Big(\frac{x_{t-1} + x_{t-2}}{1 + x_{t-1}^2 + x_{t-2}^2}\Big)^2 + \varepsilon_t, \quad t=1,...,1250\]

\[\beta_1 = 0.47, \beta_2=-0.45\]

\[v_t = 0.55v_{t-1} - 0.42v_{t-1} + \delta_t, \quad x_t = 0.8\sin(2 \pi x_{t-1}) - 0.2\cos(2 \pi x_{t-2}) + \eta_t\]

\[\varepsilon_t \sim \mathcal{N}(0,0.5^2), \quad \delta_t,\eta_t \sim \text{Unif}[-0.5,0.5]\]

<p>We then compare the following:</p>

<ol>
  <li>A parametric model that is specified to the true functional form (usually unknown to the researcher, but should yield the best results</li>
  <li>A parametric model that will have the nonlinear part misspecified</li>
  <li>A fully nonparametric ANN</li>
  <li>A “hybrid” semiparametric ANN that contains both linear terms and a nonparametric correction term</li>
  <li>A semiparametric model where the nonlinear term is estimated by a kernel density estimator</li>
</ol>

<p>Note, that we are in the low dimensional case here, so we would expect the kernel based model to perform better than the ANN. We compare both the RMSE and  this time around also the integrated squared bias and variance for the semiparametric estimators:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Model</th>
      <th style="text-align: center">RMSE</th>
      <th style="text-align: center">\(\int \text{Bias}^2\)</th>
      <th style="text-align: center">\(\int \text{Var}_e\)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">True</td>
      <td style="text-align: center">0.4944</td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Linear</td>
      <td style="text-align: center">0.5199</td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">ANN</td>
      <td style="text-align: center">0.5495</td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
    </tr>
    <tr>
      <td style="text-align: center">Semi-ANN</td>
      <td style="text-align: center">0.5061</td>
      <td style="text-align: center">0.0012</td>
      <td style="text-align: center">0.0072</td>
    </tr>
    <tr>
      <td style="text-align: center">Semi-Kernel</td>
      <td style="text-align: center"> </td>
      <td style="text-align: center">0.0012</td>
      <td style="text-align: center">0.0061</td>
    </tr>
  </tbody>
</table>

<p>Again for each model 50 simulations were carried out. Clearly, the true model beats any other estimation - but more interestingly the semiparametric specification using a neural network performed better than the fully nonparametric specification of the neural network. Inference wise, it is still outperformed by the Kernel based semiparametric model though.</p>

<p>The linear model should still provide unbiased estimates, but they should be less efficient than the same parameters estimated by the semiparametric ANN, as can be seen in the figures below:</p>

<p><img src="/assets/img/figure_parametric_estimate.png" alt="drawing" width="400" class="center">
<img src="/assets/img/figure_standard_errors.png" alt="drawing" width="400" class="center"></p>

<p>So even if a fully nonparametric estimator is available, it might be worth considering a semiparametric approach, not only because it seems to work better in practice, but also because we can infer properties of our model parameters.</p>


  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2023 Philipp  Ratz.
    Based on <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
